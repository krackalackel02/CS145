{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS145 Introduction to Data Mining - Assignment 5\n",
    "## Deadline: 11:59PM, June 1, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "Each assignment is structured as a Jupyter notebook (though we display it here in Markdown form). You will encounter two types of problems: **write-up problems** and **coding problems**:\n",
    "\n",
    "1. **Write-up Problems**: These are theoretical questions where you should demonstrate understanding of lecture concepts. Provide explanations, derivations, and proofs where necessary. Use LaTeX math for clarity.\n",
    "\n",
    "2. **Coding Problems**: You will implement and test data mining or machine learning algorithms. The code must be runnable (i.e., no syntax errors). **TODO** blocks indicate sections for you to complete.\n",
    "\n",
    "### Submission Requirements\n",
    "- Submit your `.ipynb` file (and any supplementary files, if needed) to GradeScope in BruinLearn before the deadline.\n",
    "- Late submissions up to 24 hours are accepted with a penalty factor of $\\mathbf{1}(t \\le 24) e^{-(\\ln(2)/12)t}$.\n",
    "\n",
    "### Collaboration and Integrity\n",
    "- Collaborating on ideas is encouraged, but all submitted work must be your own. If you discuss with peers or use external references, clearly cite them.\n",
    "- Any form of cheating (e.g., unauthorized code or solutions) will be reported to the university's Office of the Dean of Students.\n",
    "\n",
    "---\n",
    "\n",
    "# Outline\n",
    "\n",
    "1. **Part 1: Write-up**\n",
    "   - Q1: Large Language Models (LLMs): A Pro and a Con\n",
    "   - Q2: pLSA Model: Manual Calculation of $c$ and $\\beta$\n",
    "\n",
    "2. **Part 2: Coding**\n",
    "   - Q3: Spam Detection with Logistic Regression & Naive Bayes\n",
    "   - Q4: Implementing Transformers (Attention and Multi-Head Attention)\n",
    "   - Q5: Time-Series Sequence Prediction with Yahoo Stock Prices (AR vs. RNN)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Write-up\n",
    "\n",
    "## Q1: Large Language Models: A Pro and a Con\n",
    "**Objective**  \n",
    "Large Language Models (LLMs) such as GPT-4, PaLM, etc., are widely used in industry. Their abilities, however, come with potential pitfalls.\n",
    "\n",
    "**Tasks**  \n",
    "1. **Pro Example**: Provide an example of how an LLM might excel in a practical task (e.g., drafting emails, summarizing documents, coding assistance, chat-based tutoring, etc.). Write a short paragraph describing what you did, the prompt you used, and how the model responded. **(8 pts)**\n",
    "2. **Con Example**: Provide an example scenario where an LLM's limitations became apparent (e.g., factual inaccuracies, biased output, difficulty with reasoning tasks, or security concerns). Again, share your prompt and the response to highlight the limitation. **(8 pts)**\n",
    "3. **Experiment Setup**: Describe the interface or Web UI you used (e.g., ChatGPT online, Bard, Bing Chat, etc.). No need to show detailed logs—just summarize your approach. **(4 pts)**\n",
    "\n",
    "Ensure you highlight what was \"good\" or \"bad\" about each scenario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your responses here. ]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q2: pLSA Model - Manual Calculation\n",
    "**Objective**  \n",
    "Recall that Probabilistic Latent Semantic Analysis (pLSA) involves an E-step and M-step. You will do a small calculation with a made-up dataset to solidify your understanding.\n",
    "\n",
    "Let's define:\n",
    "- $ K = 2 $ topics\n",
    "- A small vocabulary with 3 words (w1, w2, w3)\n",
    "- A document-term matrix that reflects how many times a word appears in each document (table below)\n",
    "\n",
    "|       | w1 | w2 | w3 |\n",
    "|-------|----|----|----|\n",
    "| d1    | 3  | 1  | 0  |\n",
    "| d2    | 0  | 2  | 2  |\n",
    "\n",
    "We assume some initial values for $ p(z \\mid d) $ and $ p(w \\mid z) $. Suppose after the E-step, the following $c(d,z,w)$ values (expected counts of word $w$ in document $d$ being assigned to topic $z$) are obtained:\n",
    "\n",
    "**For Topic $z_1$**:\n",
    "| $c(d, z_1, w)$ | $w_1$ | $w_2$ | $w_3$ |\n",
    "|----------------|-------|-------|-------|\n",
    "| $d_1$          | 0.3   | 0.1   | 0     |\n",
    "| $d_2$          | 0     | 0.8   | 1.5   |\n",
    "\n",
    "**For Topic $z_2$**:\n",
    "| $c(d, z_2, w)$ | $w_1$ | $w_2$ | $w_3$ |\n",
    "|----------------|-------|-------|-------|\n",
    "| $d_1$          | 2.7   | 0.9   | 0     |\n",
    "| $d_2$          | 0     | 1.2   | 0.5   |\n",
    "\n",
    "**Tasks**  \n",
    "1. **M-Step for $ p(w \\mid z) $**: Show how you calculate $\\beta_{z,w} = p(w \\mid z)$ given the partial counts $c(d,z,w)$.  **(8 pts)**  \n",
    "2. **M-Step for $ p(z \\mid d) $**: Show how you calculate $p(z \\mid d)$.  **(6 pts)**  \n",
    "3. **Interpretation**: Suppose one topic's distribution heavily favors w1, and the other heavily favors w3. How would you interpret that in terms of the potential \"themes\" of the documents?  **(6 pts)**\n",
    "\n",
    "**Deliverable**: Provide your handwritten or typed calculations in your write-up. Reference the relevant equations from class for pLSA's E-step and M-step, and show your derivations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your responses here. ]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "# Part 2: Coding\n",
    "\n",
    "## Q3: Spam Detection with Logistic Regression & Naive Bayes (Coding)\n",
    "**Objective**  \n",
    "You will analyze a real, highly imbalanced spam‐detection dataset and compare the performance of two classifiers: **Logistic Regression** (discriminative) and **Naive Bayes** (generative).\n",
    "\n",
    "**Dataset**  \n",
    "We will use the **UCI Spambase** dataset (57 continuous features extracted from e-mails; 39 % of the samples are spam).  \n",
    "Load it directly from OpenML. \n",
    "\n",
    "**Tasks (20 pts total)**  \n",
    "1. **Data Loading & Exploration**: Download the dataset as shown above, print basic descriptive statistics, and confirm the degree of class imbalance. **(3 pts)**  \n",
    "2. **Train/Validation Split**: Create an 80 / 20 stratified split that preserves the spam / non-spam ratio. **(2 pts)**  \n",
    "3. **Logistic Regression Model**: Train a scikit-learn `LogisticRegression` (solver = `liblinear`, `class_weight='balanced'`) on the training set. **(4 pts)**  \n",
    "4. **Naive Bayes Model**: Train a `GaussianNB` (or `MultinomialNB` after min-max scaling and discretization) on the same training data. **(3 pts)**  \n",
    "5. **Evaluation Metrics**: For both classifiers, compute **precision, recall, F1-score, ROC AUC**, and plot the ROC curve on the **validation** set. **(4 pts)**  \n",
    "6. **Discussion**: In 2-3 sentences, compare the two models' performance and comment on how class imbalance affected each approach. **(4 pts)**\n",
    "\n",
    "**Starter Code Skeleton**  \n",
    "Fill in the TODO blocks and leave `raise NotImplementedError` where indicated so that automated grading can detect incomplete work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Returns X (pandas.DataFrame) and y (pandas.Series)\n",
    "X, y = fetch_openml(\"spambase\", version=1, as_frame=True, return_X_y=True, parser=\"auto\")\n",
    "print(X.shape, y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, RocCurveDisplay)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------- 1) Load data ----------------\n",
    "X, y = fetch_openml(\"spambase\", version=1, as_frame=True, return_X_y=True, parser=\"auto\")\n",
    "print(\"Class distribution:\\n\", y.value_counts())\n",
    "\n",
    "# ---------------- 2) Train / Val split --------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Optional: feature scaling (logistic regression benefits)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "\n",
    "# ---------------- 3) Logistic Regression ------\n",
    "log_reg = LogisticRegression(solver=\"liblinear\", class_weight=\"balanced\")\n",
    "# TODO: fit and generate validation predictions  # **(4 pts)**\n",
    "raise NotImplementedError\n",
    "\n",
    "# ---------------- 4) Naive Bayes --------------\n",
    "nb = GaussianNB()\n",
    "# TODO: fit and generate validation predictions  # **(3 pts)**\n",
    "raise NotImplementedError\n",
    "\n",
    "# ---------------- 5) Evaluation ---------------\n",
    "# TODO: compute precision, recall, F1, ROC-AUC for *each* model\n",
    "#       and plot ROC curves on the same figure.                  # **(4 pts)**\n",
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Q4: Implementing Transformers (Attention and Multi-Head Attention)\n",
    "In this section, you will implement the core components of a Transformer, focusing specifically on attention and multi-head attention. We will not implement positional encodings or feed-forward networks (unless you want to explore further).\n",
    "\n",
    "### Q4.1 Single-Head Attention\n",
    "**Recap**  \n",
    "For queries $Q$, keys $K$, and values $V$, we define:\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q,K,V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
    "$$\n",
    "\n",
    "where $d_k$ is the dimensionality of the key vectors.\n",
    "\n",
    "**Starter Code (PyTorch)**  \n",
    "The cell below provides a minimal scaffold that you must complete. **Fill in each TODO** and leave the `raise NotImplementedError` statements in place so that automated grading can detect incomplete work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def scaled_dot_product_attention(Q: torch.Tensor,\n",
    "                                 K: torch.Tensor,\n",
    "                                 V: torch.Tensor,\n",
    "                                 mask: torch.Tensor = None) -> torch.Tensor:\n",
    "    \"\"\"Compute scaled dot-product attention (single head).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Q : torch.Tensor, shape (B, N, d_k)\n",
    "    K : torch.Tensor, shape (B, M, d_k)\n",
    "    V : torch.Tensor, shape (B, M, d_v)\n",
    "    mask : optional tensor broadcastable to (B, N, M); elements that should be\n",
    "            *ignored* must be set to -inf **before** the softmax.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : torch.Tensor, shape (B, N, d_v)\n",
    "    \"\"\"\n",
    "    # TODO 1) compute raw attention scores    **(3 pts)**\n",
    "    # TODO 2) scale by sqrt(d_k)              **(2 pts)**\n",
    "    # TODO 3) (optional) add mask             **(1 pt)**\n",
    "    # TODO 4) apply softmax over keys (dim=-1) **(2 pts)**\n",
    "    # TODO 5) multiply by V to obtain output  **(0 pts - included above)**\n",
    "    raise NotImplementedError\n",
    "\n",
    "# Quick shape check (should run without modification once you finish the TODOs)  # **(2 pts)**\n",
    "if __name__ == \"__main__\":\n",
    "    B, N, M, d_k, d_v = 2, 4, 4, 8, 8\n",
    "    Q = torch.randn(B, N, d_k)\n",
    "    K = torch.randn(B, M, d_k)\n",
    "    V = torch.randn(B, M, d_v)\n",
    "    out = scaled_dot_product_attention(Q, K, V)\n",
    "    print(\"Output shape:\", out.shape)  # Expected: (2, 4, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.2 Multi-Head Attention\n",
    "**Starter Code (PyTorch)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int = 8):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        # Learned projections\n",
    "        self.W_Q = torch.nn.Linear(d_model, d_model)\n",
    "        self.W_K = torch.nn.Linear(d_model, d_model)\n",
    "        self.W_V = torch.nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Final output projection\n",
    "        self.W_O = torch.nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        \"\"\"Applies multi-head attention.\n",
    "\n",
    "        Q, K, V : shape (B, N, d_model)\n",
    "        mask    : optional, broadcastable to (B, num_heads, N, M)\n",
    "        returns : shape (B, N, d_model)\n",
    "        \"\"\"\n",
    "        # TODO 1) project Q, K, V and split into heads (B, num_heads, N, d_k)  **(5 pts)**\n",
    "        # TODO 2) call scaled_dot_product_attention on each head (vectorised)  **(3 pts)**\n",
    "        # TODO 3) concatenate heads and apply final linear projection  **(0 pts - included above)**\n",
    "        raise NotImplementedError\n",
    "\n",
    "# Synthetic test (runs after you implement forward)  # **(2 pts)**\n",
    "if __name__ == \"__main__\":\n",
    "    B, N, d_model = 2, 5, 32\n",
    "    mha = MultiHeadAttention(d_model=d_model, num_heads=4)\n",
    "    x = torch.randn(B, N, d_model)\n",
    "    y = mha(x, x, x)\n",
    "    print(\"Multi-head output shape:\", y.shape)  # Expected: (2, 5, 32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q5: Time-Series Sequence Prediction with Yahoo Stock Prices (AR vs. RNN)\n",
    "\n",
    "You will use daily adjusted closing prices for **Apple Inc. (ticker: `AAPL`)** obtained from Yahoo Finance via the [`yfinance`](https://pypi.org/project/yfinance/) API. If you prefer to study another large-cap equity, simply change the ticker symbol in the starter code.  \n",
    "\n",
    "> **Package note**: Install missing Python packages with `pip install yfinance statsmodels scikit-learn torch` (or the equivalent `conda`/`mamba` command).\n",
    "\n",
    "### Q5.1 Data Pre-processing\n",
    "Starter code below illustrates how to download the data, create sliding-window sequences, and generate train/validation splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from typing import Tuple\n",
    "\n",
    "# --------------- Download daily data ---------------\n",
    "TICKER = \"AAPL\"\n",
    "# The yfinance default `auto_adjust` became True in version ≥0.2; we set it to False to retain the\n",
    "# separate \"Adj Close\" column.  If you upgrade yfinance and still don't see \"Adj Close\", fall back\n",
    "# to the regular \"Close\" column.\n",
    "DATA = yf.download(TICKER, start=\"2010-01-01\", end=\"2024-01-01\", progress=False, auto_adjust=False)\n",
    "prices = DATA.get(\"Adj Close\", DATA[\"Close\"]).dropna().reset_index(drop=True)\n",
    "\n",
    "# --------------- Train / Validation split ----------\n",
    "train_ratio = 0.8\n",
    "split_idx = int(len(prices) * train_ratio)\n",
    "train_series = prices.iloc[:split_idx]\n",
    "val_series   = prices.iloc[split_idx:]\n",
    "\n",
    "WINDOW = 3  # lag order p\n",
    "\n",
    "def make_sequences(series: pd.Series, window: int = WINDOW) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Create (X, y) pairs using a sliding window.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(window, len(series)):\n",
    "        X.append(series.iloc[i-window:i].values)  # previous p prices\n",
    "        y.append(series.iloc[i])                  # current price\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = make_sequences(train_series)\n",
    "X_val,   y_val   = make_sequences(val_series)\n",
    "print(\"Train sequences:\", X_train.shape, \"| Val sequences:\", X_val.shape)  # **(Data preprocessing: 4 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Q5.2 Autoregressive (AR) Model\n",
    "Fill in the missing sections of the function below **or** feel free to re-implement using `statsmodels`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "def evaluate_ar(train_series: pd.Series, val_series: pd.Series, p: int = WINDOW) -> float:\n",
    "    \"\"\"Fit an AR(p) model on `train_series` and return the validation MSE.\"\"\"  # **(6 pts)**\n",
    "    # TODO: fit model (hint: AutoReg in statsmodels)\n",
    "    # TODO: generate forecasts of length = len(val_series)\n",
    "    # TODO: compute and return mean_squared_error\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.3 RNN / LSTM Model\n",
    "The skeleton below defines a lightweight LSTM-based regressor. Complete the forward pass **and** the training loop of `train_rnn`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class PriceLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim: int = 32, num_layers: int = 1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc   = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x: (batch, seq_len=WINDOW, 1)\"\"\"\n",
    "        # TODO: implement forward pass (LSTM -> final hidden state -> fc)  # **(5 pts)**\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def train_rnn(model: nn.Module, X_train: np.ndarray, y_train: np.ndarray,\n",
    "              X_val: np.ndarray,   y_val: np.ndarray,\n",
    "              epochs: int = 15, lr: float = 1e-3) -> None:\n",
    "    \"\"\"Train `model` using mean-squared error loss and print val MSE each epoch.\"\"\"  # **(3 pts)**\n",
    "    # TODO: write training loop (optimizer, criterion, batching optional)\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training both models, report the validation MSEs and **briefly discuss** which approach performed better and why.  **(2 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[TODO: Write your responses here. ]**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
