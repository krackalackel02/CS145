{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTQUJ2NRloAc"
      },
      "source": [
        "# CS145 Introduction to Data Mining - Assignment 1\n",
        "## Deadline: 11:59PM, January 14, 2025\n",
        "\n",
        "## Instructions\n",
        "Each assignment is structured as a Jupyter notebook, offering interactive tutorials that align with our lectures. You will encounter two types of problems: *write-up problems* and *coding problems*.\n",
        "\n",
        "1. **Write-up Problems:** These problems are primarily theoretical, requiring you to demonstrate your understanding of lecture concepts and to provide mathematical proofs or derivations. Your answers should include sufficient steps for the mathematical derivations.\n",
        "2. **Coding Problems:** Here, you will be engaging with practical coding tasks. These may involve completing code segments provided in the notebooks or developing models from scratch.\n",
        "\n",
        "To ensure clarity and consistency in your submissions, please adhere to the following guidelines:\n",
        "\n",
        "* For write-up problems, use Markdown bullet points to format text answers. Also, express all mathematical equations using $\\LaTeX$ and avoid plain text such as `x0`, `x^1`, or `R x Q` for equations.\n",
        "* For coding problems, comment on your code thoroughly for readability and ensure your code is executable. Non-runnable code may lead to a loss of **all** points. Coding problems have automated grading, and altering the grading code will result in a deduction of **all** points.\n",
        "* Your submission should show the entire process of data loading, preprocessing, model implementation, training, and result analysis. This can be achieved through a mix of explanatory text cells, inline comments, intermediate result displays, and experimental visualizations.\n",
        "\n",
        "### Submission Requirements\n",
        "\n",
        "* Submit your ipynb through GradeScope in BruinLearn. Submission in PDF format will not be graded.\n",
        "* Late submissions are allowed up to 24 hours post-deadline with a penalty factor of\n",
        "  $$\n",
        "  \\mathbf{1}(t \\leq 24) \\, e^{-(\\ln(2)/12) t}.\n",
        "  $$\n",
        "\n",
        "### Collaboration and Integrity\n",
        "\n",
        "* Collaboration is encouraged, but all final submissions must be your own work. Please acknowledge any collaboration or external sources used, including websites, papers, and GitHub repositories.\n",
        "* Any suspicious cases of academic misconduct will be reported to The Office of the Dean of Students.\n",
        "\n",
        "---\n",
        "\n",
        "## Outline\n",
        "* **Part 1: Write-up (90 points)**\n",
        "  1. Introduction & Know Your Data  \n",
        "  2. Linear Regression  \n",
        "  3. Logistic Regression & Classification\n",
        "* **Part 2: Coding (40 points)**\n",
        "  1. Exploratory Data Analysis & Preprocessing (8 points)  \n",
        "  2. Linear Regression with Regularization and Cross Validation (12 points)  \n",
        "  3. Logistic Regression with Regularization and Cross Validation (10 points)  \n",
        "  4. Implement Gradient Descent and Compare with Sklearn (10 points)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av8IckcnloAd"
      },
      "source": [
        "## Part 1: Write-up (90 points)\n",
        "\n",
        "### 1. Introduction & Know Your Data (30 points)\n",
        "\n",
        "1. **One-Hot Encoding (10 points)**  \n",
        "   One-hot-encoding is a process of converting a single categorical variable with $k$ discrete values into $k$ binary variables (indicators). In which scenarios is one-hot-encoding particularly important, and in which cases might it be inappropriate or unnecessary? Consider the following examples and state whether or not you would apply one-hot-encoding, and why:\n",
        "   - (a) Zipcode  \n",
        "   - (b) Income Level (e.g., discrete categories such as `low`, `medium`, `high`)  \n",
        "   - (c) Age  \n",
        "   - (d) Cuisine Category  \n",
        "   - (e) All the states in the U.S.  \n",
        "\n",
        "2. **True/False: Simple Explanations (10 points)**  \n",
        "   For each statement below, write **True** or **False**, and provide a **brief** justification (1-3 sentences) for your answer:\n",
        "   - (a) Categorical variables can only be used when the number of categories is finite.  \n",
        "   - (b) *Correlation* refers to the linear dependence between two variables.  \n",
        "   - (c) Supervised learning and unsupervised learning differ in that supervised learning requires labeled data while unsupervised learning does not.  \n",
        "   - (d) Median is usually preferred over mean as a summary statistic when there are extreme outliers.  \n",
        "   - (e) Sample variance is an unbiased estimator of the population variance.\n",
        "\n",
        "3. **Data Preprocessing (10 points)**  \n",
        "   (a) Why are normalization or standardization useful steps in data preprocessing?  \n",
        "   (b) List two ways to normalize a dataset.  \n",
        "   (c) Name two ways to deal with missing values and explain when/why each approach might be used.  \n",
        "   (d) Suppose you have a table with 4 columns: 3 numeric columns and 1 categorical column. You want to predict one numeric column from the remaining three columns.  \n",
        "   - What type of machine learning task is this?  \n",
        "   - What preprocessing steps might you consider for the 3 feature columns?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpkIIM6VloAd"
      },
      "source": [
        "**[TODO: Provide your responses here. ]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsA6TruXloAd"
      },
      "source": [
        "### 2. Linear Regression (30 points)\n",
        "\n",
        "Consider a dataset with $n$ samples and $d$ features, where $\\boldsymbol{X} \\in \\mathbb{R}^{n \\times d}$ is the feature matrix and $\\boldsymbol{y} \\in \\mathbb{R}^n$ is the target vector.\n",
        "\n",
        "1. **Closed-form for Ridge Regression (10 points)**  \n",
        "   Recall the Ridge regression objective:  \n",
        "   $$\n",
        "   J(\\boldsymbol{w}) = \\frac{1}{2n} \\sum_{i=1}^n \\bigl(\\boldsymbol{x}_i^\\top \\boldsymbol{w} - y_i\\bigr)^2 \\;+\\; \\frac{\\lambda}{2n}\\|\\boldsymbol{w}\\|_2^2,\n",
        "   $$\n",
        "   where $\\boldsymbol{w}\\in \\mathbb{R}^d$, $\\lambda \\ge 0$ is the regularization parameter, and $\\|\\boldsymbol{w}\\|_2^2 = \\sum_{j=1}^d w_j^2$.  \n",
        "   **Task:** Derive the closed-form solution for $\\boldsymbol{w}^\\star$. Show your steps:\n",
        "   - Write $J(\\boldsymbol{w})$ in matrix form.  \n",
        "   - Take the gradient w.r.t.\\ $\\boldsymbol{w}$.  \n",
        "   - Set the gradient to zero and solve for $\\boldsymbol{w}^\\star$.  \n",
        "\n",
        "2. **Regularization Intuition (5 points)**  \n",
        "   Recall the question from lecture: *When $\\lambda$ is very large (i.e., goes to infinity) in Ridge regression, what happens to the magnitude of the weights?* Explain why this leads to a simpler or more complex model.\n",
        "\n",
        "3. **Bias and Variance in High-degree Polynomials (5 points)**  \n",
        "   Suppose you fit a polynomial regression model with a very high polynomial degree to a small dataset:\n",
        "   - (a) How does this typically affect the model’s bias and variance?  \n",
        "   - (b) In practice, what approaches might help mitigate overfitting in a high-degree polynomial scenario?\n",
        "\n",
        "4. **Ridge vs. No Regularization (5 points)**  \n",
        "   If you train a model without any regularization vs. a model with $\\lambda > 0$ (Ridge regression), how can this alter the learned weights and generalization performance? Provide a short explanation.\n",
        "\n",
        "5. **2D Residual Analysis (5 points)**  \n",
        "   You have data with two features $X_1, X_2$ and one target $Y$. You fit a linear regression model:  \n",
        "   $$\n",
        "   \\hat{Y} = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2.\n",
        "   $$\n",
        "   If you plot $(\\hat{Y} - Y)$ (the residual) against $X_1$ and $X_2$ and observe distinct patterns, what might that suggest about your model or data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJbY6V4xloAe"
      },
      "source": [
        "**[TODO: Provide your responses here. ]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mShRj0LQloAe"
      },
      "source": [
        "### 3. Logistic Regression & Practical Classification (30 points)\n",
        "\n",
        "1. **Odds and Log-Odds (6 points)**  \n",
        "   (a) Given the odds $\\frac{P(Y=1)}{1 - P(Y=1)}$, what is its numerical range?  \n",
        "   (b) What is the range of the log-odds $\\ln \\left(\\frac{P(Y=1)}{1 - P(Y=1)}\\right)$?  \n",
        "   (c) When $P(Y=1) = 0.5$, what is the value of $\\ln(\\text{odds})$?\n",
        "\n",
        "2. **Logistic Regression Model (4 points)**  \n",
        "   Write down the logistic regression model for a single feature $X$. Briefly interpret the meaning of the learned parameter $\\beta_1$ in a logistic regression context.\n",
        "\n",
        "3. **Regularization in Logistic Regression (5 points)**  \n",
        "   Similar to Ridge regression for linear models, logistic regression can also include $L_2$ penalty on the weights.  \n",
        "   - (a) When $\\lambda$ is large, do we expect more or less complex decision boundaries? Why?  \n",
        "   - (b) Would the gradient of the weights ever become exactly zero in the presence of an extremely rare but always “positive” feature without regularization?\n",
        "\n",
        "4. **Classification Threshold (5 points)**  \n",
        "   Suppose you have a logistic regression model that predicts $P(Y=1|X)$. In practice, how would you convert these probabilities into a binary classification label (0 or 1)? Which threshold is commonly used, and why might one choose a different threshold?\n",
        "\n",
        "5. **Evaluation Metrics (10 points)**  \n",
        "   (a) Define **Precision** and **Recall**.  \n",
        "   (b) Show how they combine in the $F_1$ measure.  \n",
        "   (c) If you had a highly imbalanced dataset (e.g. 99% negatives, 1% positives), why might accuracy alone be misleading?  \n",
        "   (d) What would be the accuracy of a classifier that predicts **all negative** in the above scenario?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w-_rkjQloAe"
      },
      "source": [
        "**[TODO: Provide your responses here. ]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfvduG_4loAe"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Coding (40 points)\n",
        "\n",
        "Below, we will work with real-world data to practice data preprocessing, train models, and experiment with regularization.\n",
        "\n",
        "### Overview\n",
        "\n",
        "**Datasets**  \n",
        "- **Housing Dataset (for Regression):** We will use a (smaller) version of the California Housing dataset to predict continuous target values (housing prices).\n",
        "- **Heart Disease Dataset (for Classification):** We will use a simplified heart disease dataset (`heart.csv`), with a binary label indicating the presence or absence of heart disease.\n",
        "\n",
        "> **Files you will need:**\n",
        "> - `housing.csv`\n",
        "> - `heart.csv`  \n",
        "\n",
        "> **Important**: For all plots, please use `matplotlib` (or `seaborn`).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbthO2BRloAe"
      },
      "source": [
        "### 1. Exploratory Data Analysis & Preprocessing (8 points)\n",
        "\n",
        "#### 1.1 Load and Explore the Datasets (4 points)\n",
        "\n",
        "**Housing (Regression)**  \n",
        "1. Load the `housing.csv` file into a Pandas DataFrame.  \n",
        "2. Print out the first 5 rows.  \n",
        "3. Display a summary (using `df.info()`) of data types and missing values.  \n",
        "4. Create histograms of at least two numeric columns (e.g., `median_income`, `median_house_value`). Discuss any interesting observations in 1-2 sentences.\n",
        "\n",
        "**Heart Disease (Classification)**  \n",
        "1. Load the `heart.csv` file into a separate Pandas DataFrame.  \n",
        "2. Print out the first 5 rows.  \n",
        "3. Display a summary of data types and check for missing values.  \n",
        "4. Create histograms or bar plots of at least two features (e.g., `age`, `chol`, or a categorical variable). Briefly comment on any skewness or notable patterns.\n",
        "\n",
        "#### 1.2 Data Cleaning & Feature Engineering (4 points)\n",
        "\n",
        "- For **both** datasets:\n",
        "  1. Identify if there are any **missing** values and decide how to handle them (drop or impute). Justify your choice in a text cell.  \n",
        "  2. If there are categorical variables (e.g., `ocean_proximity` in housing, `cp` or `thal` in heart), convert them to numeric using a method of your choice (e.g., one-hot encoding, label encoding).  \n",
        "  3. Optionally, create **at least one new feature** in one of the datasets (e.g., `rooms_per_household` in housing, or some ratio in heart data).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJp7xPculoAe"
      },
      "outputs": [],
      "source": [
        "# TODO: Data loading and EDA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load housing data\n",
        "# 2. Display the first few rows\n",
        "# 3. Show data info (e.g. housing.info())\n",
        "# 4. Plot histograms\n",
        "\n",
        "# 5. Load heart data\n",
        "# 6. Display the first few rows\n",
        "# 7. Show data info\n",
        "# 8. Plot relevant columns (bar/histogram)\n",
        "# TODO: Handle missing values if any\n",
        "# TODO: Convert categorical to numeric\n",
        "# TODO: Create at least one new feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLaqURl_loAf"
      },
      "source": [
        "### 2. Linear Regression with Regularization and Cross Validation (12 points)\n",
        "\n",
        "We will focus on the **Housing** dataset for the regression tasks.\n",
        "\n",
        "#### 2.1 Train-Test Split (2 points)\n",
        "\n",
        "Split the **housing** dataset into 80% train and 20% test. **Important**: ensure you also separate the **target** (`median_house_value`) from the input features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6TLDopSloAf"
      },
      "outputs": [],
      "source": [
        "# TODO: Housing train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example:\n",
        "# X_train, X_test, y_train, y_test = train_test_split(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raz5WIo8loAf"
      },
      "source": [
        "#### 2.2 Baseline Linear Regression + Evaluation (2 points)\n",
        "\n",
        "1. Train a standard linear regression (no regularization) on the training set.\n",
        "2. Compute the Mean Squared Error (MSE) on both the training and test sets.\n",
        "3. Print the RMSE (square root of MSE).\n",
        "4. Briefly comment in a Markdown cell: Is there a large gap between train and test RMSE?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8P4G_fYoloAf"
      },
      "outputs": [],
      "source": [
        "# TODO: Baseline Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 1. Fit\n",
        "# 2. Predict on train and test\n",
        "# 3. Compute MSE, RMSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_XgqUlsloAf"
      },
      "source": [
        "**[TODO: Provide your responses here. ]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTs0NBnSloAf"
      },
      "source": [
        "#### 2.3 Ridge Regression and Cross Validation (8 points)\n",
        "\n",
        "1. Use **Ridge** regression (`sklearn.linear_model.Ridge`) with a few different values of $\\lambda$ (called `alpha` in `sklearn`)—for example: `[0.0, 0.01, 0.1, 1.0, 10.0, 100.0]`.\n",
        "2. Use **cross validation** (`cross_val_score` or `KFold` + `for loop`) on the **training set** to estimate how well each alpha performs.\n",
        "3. Plot alpha values (x-axis) vs. average RMSE across folds (y-axis). You can also store or print these average values in a table if you prefer.\n",
        "4. Choose the alpha that yields the best average RMSE and refit a final Ridge model on the entire training set.\n",
        "5. Evaluate the final model’s performance on the test set. Compare it with the baseline from Section 2.2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4BrppiyloAf"
      },
      "outputs": [],
      "source": [
        "# TODO: Ridge regression cross validation\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# 1. alpha_list = [0.0, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
        "# 2. cross_val each alpha\n",
        "# 3. store average CV RMSE\n",
        "# 4. pick best alpha\n",
        "# 5. re-train on entire train set and evaluate on test set\n",
        "# TODO: Plot alpha vs. average CV RMSE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Something like:\n",
        "# plt.plot(alpha_list, avg_cv_mse_list, marker='o')\n",
        "# plt.xlabel(...)\n",
        "# plt.ylabel(...)\n",
        "# plt.title(...)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYtrgcBgloAf"
      },
      "source": [
        "### 3. Logistic Regression with Regularization and Cross Validation (10 points)\n",
        "\n",
        "We will focus on the **Heart Disease** dataset for classification tasks.\n",
        "\n",
        "#### 3.1 Train-Test Split (2 points)\n",
        "\n",
        "Split the **heart** dataset into 80% train and 20% test. Separate out the target column (often labeled something like `target` or `condition` in heart datasets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibBRlPCtloAf"
      },
      "outputs": [],
      "source": [
        "# TODO: Heart train-test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB9xYaxHloAf"
      },
      "source": [
        "#### 3.2 Baseline Logistic Regression (3 points)\n",
        "\n",
        "1. Train a standard logistic regression (with no regularization or `C` very large in `LogisticRegression`) on the training set.\n",
        "2. Print out classification accuracy on **both** the training and test sets.\n",
        "3. Also print out or compute other metrics such as **precision**, **recall**, or an $F_1$ score on the test set.  You can use `sklearn.metrics.classification_report` or compute manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyRS9LqYloAf"
      },
      "outputs": [],
      "source": [
        "# TODO: Logistic Regression baseline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# 1. Fit\n",
        "# 2. Evaluate (accuracy, precision, recall, f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRdbGJVgloAf"
      },
      "source": [
        "#### 3.3 Logistic Regression + Cross Validation (5 points)\n",
        "\n",
        "1. Choose a list of `C` values (the inverse of $\\lambda$ in logistic regression). For example: `[0.001, 0.01, 0.1, 1.0, 10.0, 100.0]`.\n",
        "2. Perform **cross validation** on the training set to estimate the average accuracy (or $F_1$) for each `C`.\n",
        "3. Plot the metric vs. `C` on a simple line plot.\n",
        "4. Pick the best `C` and retrain on the entire training set. Evaluate on the test set.\n",
        "5. In a short Markdown cell, discuss how increasing/decreasing `C` affects the decision boundary complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC6c6jODloAf"
      },
      "outputs": [],
      "source": [
        "# TODO: Logistic Regression cross validation for classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# 1. c_list = [...]\n",
        "# 2. for c in c_list:\n",
        "#       log_reg = LogisticRegression(C=c, solver='liblinear', ...)\n",
        "#       scores = cross_val_score(log_reg, X_train, y_train, cv=..., scoring='accuracy')\n",
        "#       ...\n",
        "# 3. Plot c vs. average CV score\n",
        "# TODO: Final evaluation on test set after picking best C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu0UvXlXloAf"
      },
      "source": [
        "**[TODO: Provide your responses here. ]**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Implement Gradient Descent and Compare with Sklearn (10 points)\n",
        "\n",
        "In this task, you will implement gradient descent from scratch to perform linear regression on the Housing dataset and compare your implementation with sklearn's `LinearRegression`.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "- **Implement Gradient Descent:**  \n",
        "  1. Use the Mean Squared Error (MSE) as the loss function:\n",
        "$$\n",
        "     J(\\boldsymbol{w}, b) = \\frac{1}{n} \\sum_{i=1}^{n}\\left(\\hat{y}_i - y_i\\right)^2, \\quad \\text{where} \\quad \\hat{y}_i = \\boldsymbol{w}^\\top \\boldsymbol{x}_i + b.\n",
        "$$\n",
        "  2. Initialize the weights and bias (you may combine them into one vector by adding a bias term to your feature matrix).\n",
        "  3. Set a learning rate (e.g., `lr = 0.01`) and choose the number of iterations.\n",
        "  4. At each iteration, compute the gradient with respect to the weights and bias, update them, and record the training MSE.\n",
        "  5. Plot the training MSE versus the iteration number to observe the convergence.\n",
        "\n",
        "- **Comparison with Sklearn:**  \n",
        "  1. After implementing gradient descent, print the final learned coefficients and bias.\n",
        "  2. Train a linear regression model using sklearn's `LinearRegression` on the same training data.\n",
        "  3. Compare the coefficients and training MSE from your implementation with those from sklearn's model.\n",
        "  4. Briefly discuss any differences observed in a Markdown cell."
      ],
      "metadata": {
        "id": "Yd82jBJV1sNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Implement Gradient Descent for Linear Regression\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assume X_train and y_train are defined from previous parts.\n",
        "# Add a column of ones to account for the bias term\n",
        "n_samples, n_features = X_train.shape\n",
        "X_train_bias = np.hstack((np.ones((n_samples, 1)), X_train))  # shape: (n_samples, n_features+1)\n",
        "\n",
        "# Initialize weights (including bias) to zeros\n",
        "w = np.zeros(n_features + 1)  # shape: (n_features+1, )\n",
        "\n",
        "# Hyperparameters\n",
        "lr = 0.01\n",
        "num_iters = 1000\n",
        "\n",
        "# To store MSE for each iteration\n",
        "mse_history = []\n",
        "\n",
        "for i in range(num_iters):\n",
        "    # TODO: Compute predictions: ...\n",
        "    # TODO: Compute error: ...\n",
        "    # TODO: Compute gradient: ...\n",
        "    # TODO: Update weights: ...\n",
        "    # TODO: Compute current MSE and append to mse_history\n",
        "    pass\n",
        "\n",
        "# Plot the training MSE vs. iteration\n",
        "plt.plot(mse_history)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Gradient Descent Convergence\")\n",
        "plt.show()\n",
        "\n",
        "# Print learned weights from gradient descent\n",
        "print(\"Learned weights from Gradient Descent:\", w)\n",
        "\n",
        "# Comparison with sklearn's LinearRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "# Combine the intercept and coefficients for comparison\n",
        "sklearn_weights = np.hstack((lin_reg.intercept_, lin_reg.coef_))\n",
        "print(\"Sklearn LinearRegression coefficients:\", sklearn_weights)"
      ],
      "metadata": {
        "id": "y0zY6DMA2Xff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pRl3Fm7loAg"
      },
      "source": [
        "**[TODO: Provide your responses here. ]**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F-NVFF4F2jvd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}